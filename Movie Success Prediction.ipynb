{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af9c9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import seaborn as sns\n",
    "\n",
    "import statsmodels.formula.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62cc1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the movies dataset into df1 and printing it to show the result.\n",
    "df1 = pd.read_csv(r\"D:\\Movies_Cleaned_Data.csv\")\n",
    "display(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8f32b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First thing we did is describing the dataset to check the values. We used pd.option to show all of the columns without skipping\n",
    "with pd.option_context(\"display.max_rows\", None, \"display.max_columns\", None):\n",
    "    display(df1.describe(include=\"all\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43793ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for duplicate rows and printing it to show the result.\n",
    "duplicateRowsDF = df1[df1.duplicated()] \n",
    "display(duplicateRowsDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c0c132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating df1 without the duplicates rows and printing it to show the result.\n",
    "df1 = df1.drop_duplicates(subset=None, keep=\"first\", inplace=False)\n",
    "df1 = df1.reset_index(drop=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e567e037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After fixing the values, we'll start showing several plots to understand the values.\n",
    "# In this cell, we plotted the relation between director name and amount of movies\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "df1.groupby(by=\"director_name\")[\"Movie Name\"].count().sort_values()[2379:2398].plot(kind=\"bar\", fontsize=12)\n",
    "plt.title(\"Director Name VS Movie name\", fontsize=18)\n",
    "plt.xlabel(\"Director Name\", fontsize=14)\n",
    "plt.ylabel(\"Amount of Movies\", fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# As we can see below, Steven Spielberg is in the first place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc85f93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A plot of the relation between first actor name and movie's gross\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "df1.groupby(by=\"actor_1_name\")[\"gross\"].sum().sort_values()[2078:2098].plot(kind=\"bar\", fontsize=12)\n",
    "plt.title(\"First Actor Name VS Gross\", fontsize=18)\n",
    "plt.xlabel(\"First Actor Name\", fontsize=14)\n",
    "plt.ylabel(\"Gross Sum\", fontsize=14)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abb087b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two plots of the relation between county and gross, language and gross\n",
    "fig, ax = plt.subplots(figsize=(16,12))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "df1.groupby(by=\"country\")[\"gross\"].sum().sort_values()[56:66].plot(kind=\"bar\", fontsize=12)\n",
    "plt.title(\"Country VS Gross\", fontsize=18)\n",
    "plt.xlabel(\"Country\", fontsize=14)\n",
    "plt.ylabel(\"Gross Sum\", fontsize=14)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "df1.groupby(by=\"language\")[\"gross\"].sum().sort_values()[42:47].plot(kind=\"bar\", fontsize=12)\n",
    "plt.title(\"Language VS Gross\", fontsize=18)\n",
    "plt.xlabel(\"Language\", fontsize=14)\n",
    "plt.ylabel(\"Gross Sum\", fontsize=14)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd2369d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A plot of the relation between IMDB Score and a movie's budget\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "plt.scatter(x=df1[\"imdb_score\"], y=df1[\"budget\"], marker=\"D\")\n",
    "plt.ticklabel_format(style=\"plain\")\n",
    "plt.title(\"IMDB Score VS Movie's Budget\", fontsize=18)\n",
    "plt.xlabel(\"IMDB Score\", fontsize=14)\n",
    "plt.ylabel(\"Movie's Budget\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00efa7f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fixing the missing values with filling None in any Nan category feature and 0.0 or mean in any numeric feature.\n",
    "df1[\"director_name\"] = df1[\"director_name\"].fillna(\"None\")\n",
    "\n",
    "df1[\"actor_1_name\"] = df1[\"actor_1_name\"].fillna(\"None\")\n",
    "\n",
    "df1[\"budget\"] = df1[\"budget\"].fillna(df1[\"budget\"].mean()).astype(np.int)\n",
    "df1[\"gross\"] = df1[\"gross\"].fillna(0.0).astype(np.float)\n",
    "df1[\"num_critic_for_reviews\"] = df1[\"num_critic_for_reviews\"].fillna(0.0).astype(np.float)\n",
    "df1[\"num_user_for_reviews\"] = df1[\"num_user_for_reviews\"].fillna(0.0).astype(np.float)\n",
    "\n",
    "df1[\"language\"] = df1[\"language\"].fillna(\"None\")\n",
    "df1[\"country\"] = df1[\"country\"].fillna(\"None\")\n",
    "df1[\"title_year\"] = df1[\"title_year\"].fillna(df1[\"title_year\"].mean()).astype(np.int)\n",
    "\n",
    "# Describing df1 again to show the result\n",
    "with pd.option_context(\"display.max_rows\", None, \"display.max_columns\", None):\n",
    "    display(df1.describe(include=\"all\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97472543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A plot of the relation between year and IMDB score\n",
    "major_movies = df1[df1[\"num_voted_users\"] >= 25000]\n",
    "major_movies.plot.scatter(\"title_year\", \"imdb_score\", figsize=(12, 8), alpha=0.4)\n",
    "plt.title(\"Year VS IMDB Score\", fontsize=18)\n",
    "plt.xlabel(\"Year\", fontsize=14)\n",
    "plt.ylabel(\"IMDB Score\", fontsize=14)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf29586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A plot of the relation between IMDB Score and a movie's budget\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "plt.scatter(x=df1[\"imdb_score\"], y=df1[\"budget\"], marker=\"D\")\n",
    "plt.ticklabel_format(style=\"plain\")\n",
    "plt.title(\"IMDB Score VS Movie's Budget\", fontsize=18)\n",
    "plt.xlabel(\"IMDB Score\", fontsize=14)\n",
    "plt.ylabel(\"Movie's Budget\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0beca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting DF3\n",
    "df3 = df1[[\"title_year\",\"budget\", \"gross\", \"cast_total_facebook_likes\", \"num_user_for_reviews\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d265b9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting our X as lables (all our features and data) and y as our target (IMDB score).\n",
    "y = np.array(df1[\"imdb_score\"], dtype=int)\n",
    "print(\"Minimum value:\", np.min(y))\n",
    "print(\"Median value:\", np.median(y))\n",
    "print(\"Maximum value:\", np.max(y))\n",
    "\n",
    "X = np.array(df3.values, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ec8cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First of all, we developed a k-NN classification model for the data:\n",
    "\n",
    "# Imports and setup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Split dataset into train and test data.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Create k-NN classifier with n_neighbors=3.\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Fit the classifier to the data.\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Check accuracy of our model on the test data.\n",
    "print(\"Accuracy with k=3 is:\", knn.score(X_test, y_test))\n",
    "\n",
    "# Secondly, we checked which value of k between 1 to 17 step 2 is the best choise of n_neighbors and printed the results.\n",
    "for k in range(1, 17, 2):\n",
    "    knn2 = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn2.fit(X_train, y_train)\n",
    "    acc = knn2.score(X_test, y_test)\n",
    "    acc_tr = knn2.score(X_train, y_train)\n",
    "    print(\"knn (k={}) Accuracy: {}, train accuracy: {}\".format(k, acc, acc_tr))\n",
    "\n",
    "# Thirdly, we calculated the error for k values between 1 to 17 step 2.\n",
    "error = []\n",
    "# Calculating error for k values between 1 to 17 step 2.\n",
    "for k in range(1, 17, 2):\n",
    "    knn3 = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn3.fit(X_train, y_train)\n",
    "    pred_k = knn3.predict(X_test)\n",
    "    error.append(np.mean(pred_k != y_test))\n",
    "\n",
    "# We used a plot to describe the error from above.\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.title(\"Error Rate K Value\", fontsize=18)  \n",
    "plt.xlabel(\"K Value\", fontsize=14)  \n",
    "plt.ylabel(\"Mean Error\", fontsize=14)\n",
    "plt.plot(range(1, 17, 2), error, color=\"red\", linestyle=\"dashed\", marker=\"o\", markerfacecolor=\"blue\", markersize=10);\n",
    "\n",
    "# As we can infer from the output below (text and plot), the best k value between 1 to 17 step 2 is 15.\n",
    "# It's accurary value is the highest and it's error is the lowest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ababaf0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# In this cell we did a cross validation using Grid Search to find the best k between 1 to 29.\n",
    "\n",
    "# We created a dictionary with a key and a value to be k values.\n",
    "k_range = list(range(1, 31, 2))\n",
    "\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "\n",
    "# Grid search to the data.\n",
    "grid = GridSearchCV(knn, param_grid, scoring=\"accuracy\", cv=5, return_train_score=True)\n",
    "\n",
    "# Fit the grid to the data.\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters to show the result.\n",
    "print(\"The best parameter set found on development set is:\", grid.best_params_)\n",
    "\n",
    "# Getting the mean values of grid search.\n",
    "means = grid.cv_results_[\"mean_test_score\"]\n",
    "\n",
    "# Print the grid scores to show the result.\n",
    "print(\"\\nGrid scores on development set:\")\n",
    "for mean, params in zip(means, grid.cv_results_[\"params\"]):\n",
    "    print(\"mean:\", mean, \"   parameters:\", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe41aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the next 2 cells, we used decision tree classifier\n",
    "\n",
    "# Imports and setup\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "import pydotplus\n",
    "from IPython.display import Image\n",
    "\n",
    "# Hacky solution of writing to files and reading again. necessary due to library bugs.\n",
    "def renderTree(my_tree, features):\n",
    "    filename = \"temp.dot\"\n",
    "    with open(filename, 'w') as f:\n",
    "        f = tree.export_graphviz(my_tree, \n",
    "                                 out_file=f, \n",
    "                                 feature_names=features, \n",
    "                                 class_names=[\"Rating 1\", \"Rating 2\", \"Rating 3\", \"Rating 4\", \"Rating 5\", \"Rating 6\", \"Rating 7\", \"Rating 8\" ,\"Rating 9\"],  \n",
    "                                 filled=True, \n",
    "                                 rounded=True,\n",
    "                                 special_characters=True)\n",
    "    dot_data = \"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        dot_data = f.read()\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "    image_name = \"temp.png\"\n",
    "    graph.write_png(image_name)  \n",
    "    display(Image(filename=image_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855f48ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f5571a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier to the data with max_depth=3.\n",
    "decisionTree = tree.DecisionTreeClassifier(max_depth=3, min_samples_leaf=2)\n",
    "\n",
    "# Splitting into test and train.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Fitting the tree with the training data.\n",
    "decisionTree = decisionTree.fit(X_train, y_train)\n",
    "\n",
    "# Predict with the training data.\n",
    "y_pred_train = decisionTree.predict(X_train)\n",
    "\n",
    "# Print the result of measure accuracy.\n",
    "print(\"The accuracy on training data is:\", metrics.accuracy_score(y_true=y_train, y_pred=y_pred_train))\n",
    "\n",
    "# Predict with the testing data.\n",
    "y_pred = decisionTree.predict(X_test)\n",
    "\n",
    "# Print the result of measure accuracy.\n",
    "print(\"The accuracy on testing data is:\", metrics.accuracy_score(y_true=y_test, y_pred=y_pred))\n",
    "renderTree(my_tree=decisionTree, features=df3.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a730be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask,request,jsonify\n",
    "from flask_cors import CORS\n",
    "import recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5be7032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the next cells we used k-means to cluster the movies into four clusters.\n",
    "\n",
    "# imports and setup \n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "# Storing all the df3 values into X\n",
    "X = df3.values\n",
    "\n",
    "# Standardize Features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Training the model\n",
    "y_pred = KMeans(n_clusters=2, n_init=1, max_iter=600).fit_predict(X_scaled)\n",
    "\n",
    "# View in a scatter\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(X[:, 2], X[:, 5], c=y_pred, marker=\"o\", s=50);\n",
    "\n",
    "# X axis = director_facebook_likes\n",
    "# Y axis = movie's gross\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04fd44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using silhouette score to find the best value of clustering from k=2 to k=6.\n",
    "\n",
    "# imports and setup \n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# A list of clusters to be tested\n",
    "range_n_clusters = [2, 3, 4, 5, 6]\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    \n",
    "    # Create a subplot with 1 row and 2 columns\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(18, 7)\n",
    "\n",
    "    # The 1st subplot is the silhouette plot. The silhouette coefficient can range from -1, 1 but in this example all lie within [-0.1, 1]\n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "    \n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette plots of individual clusters, to demarcate them clearly.\n",
    "    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "\n",
    "    # Initialize the clusterer with n_clusters value and a random generator seed of 10 for reproducibility.\n",
    "    clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "    cluster_labels = clusterer.fit_predict(X)\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples. This gives a perspective into the density and separation\n",
    "    # of the formed clusters\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    print(\"For n_clusters =\", n_clusters, \"The silhouette_score is :\", silhouette_avg)\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters):\n",
    "        # Aggregate the silhouette scores for samples belonging to cluster i and sort them\n",
    "        ith_cluster_silhouette_values =\\\n",
    "        sample_silhouette_values[cluster_labels == i]\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper), 0, ith_cluster_silhouette_values, facecolor=color,\n",
    "                          edgecolor=color, alpha=0.7)\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax1.set_title(\"The silhouette plot for the various clusters\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette coefficient of all the values\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "    \n",
    "    # Clear the yaxis labels / ticks\n",
    "    ax1.set_yticks([])\n",
    "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "    # 2nd Plot showing the actual clusters formed\n",
    "    colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
    "    ax2.scatter(X[:, 0], X[:, 1], marker=\".\", s=30, lw=0, alpha=0.7, c=colors, edgecolor=\"k\")\n",
    "\n",
    "    # Labeling the clusters\n",
    "    centers = clusterer.cluster_centers_\n",
    "    \n",
    "    # Draw white circles at cluster centers\n",
    "    ax2.scatter(centers[:, 0], centers[:, 1], marker=\"o\", c=\"white\", alpha=1, s=200, edgecolor=\"k\")\n",
    "\n",
    "    for i, c in enumerate(centers):\n",
    "        ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1, s=50, edgecolor=\"k\")\n",
    "\n",
    "    ax2.set_title(\"The visualization of the clustered data\")\n",
    "    ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
    "    ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
    "\n",
    "    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
    "                  \"with n_clusters = %d\" % n_clusters), fontsize=14, fontweight=\"bold\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "# As we can see, the best silhouette score is 0.71 for k=2, meaning, 2 different clusters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada51993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering from k = 1 to k = 10 for searching the best value\n",
    "ks = range(1, 10)\n",
    "scores = []\n",
    "\n",
    "for k in ks:\n",
    "    model = KMeans(n_clusters=k)\n",
    "    model.fit_predict(X)\n",
    "    scores.append(-model.score(X))\n",
    "\n",
    "    # View in a scatter\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(ks, scores)\n",
    "plt.ylabel(\"Total intra-cluster distance\", fontsize=14)\n",
    "plt.xlabel(\"Value of K\", fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# As we can see that, the total intra-cluster distance is large for k=1 and decreases as we increase k value, until k=2, \n",
    "# after which it tapers off and gets only marginally smaller. This indicates that k=2 is a good choice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed57e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U flask-cors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1a5765",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b221e435",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "CORS(app) \n",
    "        \n",
    "@app.route('/movie', methods=['GET'])\n",
    "def recommend_movies():\n",
    "    res = recommendation.results(request.args.get('title'))\n",
    "    return jsonify(res)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    app.run(port = 5000, debug = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb5cfea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
